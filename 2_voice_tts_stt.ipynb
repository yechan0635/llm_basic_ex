{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# openai api key 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에 저장된 환경변수 로드\n",
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 라이브러리 로딩 및 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# openai api 인증 및 openai 객체 생성\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## TTS(text to speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input = \"오늘 아침 날씨는 1도 따뜻하게 입어야해\"\n",
    ") as response:\n",
    "    response.stream_to_file(\"speech_alloy.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 음성으로 생성\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"cedar\",\n",
    "    input = \"오늘 아침 날씨는 1도 따뜻하게 입어야해\"\n",
    ") as response:\n",
    "    response.stream_to_file(\"speech_cedar.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## STT(Speech to Text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소리 파일\n",
    "\n",
    "audio_file = open(\"speech_alloy.wav\", \"rb\")\n",
    "type(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STT(Speech to Text)\n",
    "\n",
    "response = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    # response_format=\"json\",\n",
    "    # response_format=\"verbose_json\",\n",
    "    response_format=\"text\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict로 변환, json의 경우에 가능\n",
    "# dict(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 포맷 응답 결과\n",
    "# '오늘 아침 날씨는 1도, 따뜻하게 입어야 해.\\n'\n",
    "response.replace('\\n','')   # \\n 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "- STT 수행 시, 파일 클 경우 (25MB 이상)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Windows에서 FFmpeg 설치\n",
    "1. Chocolatey 설치\n",
    "Chocolatey가 설치되어 있지 않다면 다음 단계를 따라 설치할 수 있습니다:\n",
    "\n",
    "    1) 관리자 권한으로 PowerShell을 엽니다.\n",
    "\n",
    "    2) 다음 명령어를 실행하여 Chocolatey를 설치합니다:\n",
    "        \n",
    "URL에서 복사해서 설치\n",
    "      \n",
    "https://chocolatey.org/install  \n",
    "\n",
    "  3) Chocolatey 설치가 완료되면, 다음 명령어로 FFmpeg를 설치할 수 있습니다:\n",
    "\n",
    "choco install ffmpeg\n",
    "\n",
    "\n",
    "2. vs-code, 터미널 모두 닫았다가 다시 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import math\n",
    "import openai\n",
    "\n",
    "# 오디오 파일 불러오기\n",
    "audo_file = \"datas/audio.mp3\"\n",
    "song = AudioSegment.from_mp3(audo_file)\n",
    "\n",
    "# Whisper는 약 25MB 제한이 있으므로, 시간 기준으로 나누기\n",
    "# 파일 크기에 따라 다르지만, 보통 10분(600초) 정도면 20MB 내외\n",
    "chunk_length_ms = 10 * 60 * 1000  # 10분 단위로 자르기 (단위: 밀리초)\n",
    "num_chunks = math.ceil(len(song) / chunk_length_ms)\n",
    "\n",
    "print(f\"총 {num_chunks}개의 조각으로 분할합니다.\")\n",
    "\n",
    "# 전체 텍스트를 담을 리스트\n",
    "full_transcript = []\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    start = i * chunk_length_ms\n",
    "    end = min((i + 1) * chunk_length_ms, len(song))\n",
    "    chunk = song[start:end]\n",
    "    chunk_filename = f\"chunk_{i}.mp3\"\n",
    "    chunk.export(chunk_filename, format=\"mp3\")\n",
    "    \n",
    "    print(f\"{chunk_filename} 변환 중...\")\n",
    "\n",
    "    # Whisper API 호출\n",
    "    with open(chunk_filename, \"rb\") as audio_file:\n",
    "        response = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file,\n",
    "            response_format=\"text\",\n",
    "        )\n",
    "        full_transcript.append(response)\n",
    "        print(f\"{chunk_filename} 변환 완료.\")\n",
    "\n",
    "# 모든 조각의 텍스트를 합치기\n",
    "final_text = \"\\n\".join(full_transcript)\n",
    "\n",
    "# 결과 저장\n",
    "with open(\"full_transcript.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_text)\n",
    "\n",
    "print(\"전체 파일의 텍스트 변환이 완료되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
